{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOD2Ih83WjeHqvMkkZKu2kw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hibahkhan2022-rgb/Edge-AI-Product-Detection-Inferencing-Workshop/blob/main/EdgeAIProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uca3_KVnRnLA",
        "outputId": "81c1c6c7-6943-4bb5-dc87-7bfca500c02e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#mount drive to access data files\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# this is where the classification folders are under\n",
        "DATA_DIR = \"/content/gdrive/MyDrive/skincare-edge-ai/data/images/train\"\n",
        "\n",
        "assert os.path.isdir(DATA_DIR), f\"Missing: {DATA_DIR}\"\n",
        "print(\"DATA_DIR contents:\", os.listdir(DATA_DIR))\n",
        "\n",
        "# ensure class folders are present\n",
        "for cls in [\"makeup\", \"skincare\", \"scents\"]:\n",
        "    p = os.path.join(DATA_DIR, cls)\n",
        "    print(cls, \"exists:\", os.path.isdir(p), \"| num items:\", len(os.listdir(p)) if os.path.isdir(p) else \"NA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xiz0DVJR0PF",
        "outputId": "a30e7a5f-452b-4c3b-e301-fc54f688689c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA_DIR contents: ['makeup', 'scents', 'skincare']\n",
            "makeup exists: True | num items: 120\n",
            "skincare exists: True | num items: 99\n",
            "scents exists: True | num items: 115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
        "\n",
        "#initalize seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "#can run on either cpu/gpu; for further inferencing, use GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wNMXJY3S4MJ",
        "outputId": "92c94389-00b1-49ce-c2c4-419bd7ea5e26"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Using MobileNetV3 lightweight model; standard image resolution\n",
        "IMG_SIZE = 224\n",
        "\n",
        "#tranform properties for training dataset adjust for images, shadows, alignment, etc.\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "#tranform properties for validation dataset adjust for images, shadows, alignment, etc.\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "oa6e6HhvTSEI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "#checks counts per class, make sure distribution is even\n",
        "full_ds = datasets.ImageFolder(DATA_DIR, transform=train_tfms)\n",
        "class_names = full_ds.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "print(\"Classes:\", class_names)\n",
        "print(\"Total images:\", len(full_ds))\n",
        "\n",
        "counts = Counter(full_ds.targets)\n",
        "print(\"Counts per class:\")\n",
        "for i, name in enumerate(class_names):\n",
        "    print(f\"  {name:10s}: {counts.get(i, 0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OBoomriTS8q",
        "outputId": "caa1c12a-26c3-4230-fe75-8ec52818743b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['makeup', 'scents', 'skincare']\n",
            "Total images: 333\n",
            "Counts per class:\n",
            "  makeup    : 119\n",
            "  scents    : 115\n",
            "  skincare  : 99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defines batch parameters\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 2\n",
        "VAL_FRAC = 0.2\n",
        "\n",
        "#Split dataset 80/20\n",
        "val_size = int(VAL_FRAC * len(full_ds))\n",
        "train_size = len(full_ds) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(\n",
        "    full_ds,\n",
        "    [train_size, val_size],\n",
        "    generator=torch.Generator().manual_seed(SEED)\n",
        ")\n",
        "\n",
        "#change val transform\n",
        "val_ds.dataset.transform = val_tfms\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "print(\"Train size:\", len(train_ds), \"| Val size:\", len(val_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY3RSMe_TX2-",
        "outputId": "251d90f3-01b7-4ece-9230-4cd2d5c1e3c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 267 | Val size: 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load MobileNetV3 model\n",
        "weights = MobileNet_V3_Small_Weights.DEFAULT\n",
        "model = mobilenet_v3_small(weights=weights)\n",
        "\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "print(\"New head:\", model.classifier[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNq0hsG8TfRN",
        "outputId": "d5b1d219-370e-44a8-c821-cb6caf437b08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v3_small-047dcff4.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.83M/9.83M [00:00<00:00, 42.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New head: Linear(in_features=1024, out_features=3, bias=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use Cross-Entropy Loss and AdamW optimizer\n",
        "LR = 3e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "QQqncnNLTht_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "EPOCHS = 10\n",
        "os.makedirs(\"/content/models\", exist_ok=True)\n",
        "best_path = \"/content/models/mnv3_best.pth\"\n",
        "\n",
        "def batch_acc(logits, y):\n",
        "    return (logits.argmax(1) == y).float().mean().item()\n",
        "\n",
        "def train_one_epoch():\n",
        "    model.train()\n",
        "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = x.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += batch_acc(logits, y) * bs\n",
        "        n += bs\n",
        "    return total_loss / n, total_acc / n\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch():\n",
        "    model.eval()\n",
        "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
        "    for x, y in val_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "\n",
        "        bs = x.size(0)\n",
        "        total_loss += loss.item() * bs\n",
        "        total_acc  += batch_acc(logits, y) * bs\n",
        "        n += bs\n",
        "    return total_loss / n, total_acc / n\n",
        "\n",
        "best_val_acc = 0.0\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    tr_loss, tr_acc = train_one_epoch()\n",
        "    va_loss, va_acc = eval_one_epoch()\n",
        "    print(f\"Epoch {epoch:02d}/{EPOCHS} | train {tr_loss:.4f} {tr_acc:.4f} | val {va_loss:.4f} {va_acc:.4f}\")\n",
        "\n",
        "    if va_acc > best_val_acc:\n",
        "        best_val_acc = va_acc\n",
        "        torch.save({\"model_state\": model.state_dict(),\n",
        "                    \"classes\": class_names,\n",
        "                    \"img_size\": IMG_SIZE}, best_path)\n",
        "        print(f\"saved best (val acc {best_val_acc:.4f}) -> {best_path}\")\n",
        "\n",
        "print(\"Best val acc:\", best_val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SR81LwDXTnV4",
        "outputId": "7d30e9de-ed9c-4097-f933-d85649f7f66c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/10 | train 0.9299 0.6142 | val 0.6941 0.7424\n",
            "  ✅ saved best (val acc 0.7424) -> /content/models/mnv3_best.pth\n",
            "Epoch 02/10 | train 0.4765 0.8801 | val 0.5590 0.8030\n",
            "  ✅ saved best (val acc 0.8030) -> /content/models/mnv3_best.pth\n",
            "Epoch 03/10 | train 0.2572 0.9551 | val 0.5163 0.8182\n",
            "  ✅ saved best (val acc 0.8182) -> /content/models/mnv3_best.pth\n",
            "Epoch 04/10 | train 0.1487 0.9700 | val 0.4797 0.8333\n",
            "  ✅ saved best (val acc 0.8333) -> /content/models/mnv3_best.pth\n",
            "Epoch 05/10 | train 0.0784 0.9850 | val 0.5247 0.7727\n",
            "Epoch 06/10 | train 0.0380 0.9963 | val 0.5838 0.7576\n",
            "Epoch 07/10 | train 0.0202 1.0000 | val 0.6402 0.7727\n",
            "Epoch 08/10 | train 0.0188 0.9963 | val 0.5577 0.8182\n",
            "Epoch 09/10 | train 0.0074 1.0000 | val 0.5216 0.8182\n",
            "Epoch 10/10 | train 0.0060 1.0000 | val 0.5206 0.8333\n",
            "Best val acc: 0.8333333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision.models import mobilenet_v3_small\n",
        "from torch import nn\n",
        "\n",
        "#load from the best epoch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "ckpt_path = \"/content/models/mnv3_best.pth\"\n",
        "ckpt = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "class_names = ckpt[\"classes\"]\n",
        "IMG_SIZE = ckpt[\"img_size\"]\n",
        "\n",
        "model = mobilenet_v3_small(weights=None)\n",
        "in_features = model.classifier[-1].in_features\n",
        "model.classifier[-1] = nn.Linear(in_features, len(class_names))\n",
        "model.load_state_dict(ckpt[\"model_state\"])\n",
        "model = model.to(device).eval()\n",
        "\n",
        "print(\"Loaded best model. Classes:\", class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEa8C2XWU0-r",
        "outputId": "95be6cfd-10fe-4789-b284-267e99d407e0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded best model. Classes: ['makeup', 'scents', 'skincare']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#detail confusion matrix and classification report\n",
        "all_preds, all_y = [], []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "        x = x.to(device)\n",
        "        logits = model(x)\n",
        "        preds = logits.argmax(1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "        all_y.extend(y.numpy())\n",
        "\n",
        "cm = confusion_matrix(all_y, all_preds)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "print(\"\\nClassification report:\")\n",
        "print(classification_report(all_y, all_preds, target_names=class_names))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O8AeGpEU4JC",
        "outputId": "5536f7b0-ef2e-43d0-cdac-92fd4505ab8a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[25  1  4]\n",
            " [ 0 11  5]\n",
            " [ 1  0 19]]\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      makeup       0.96      0.83      0.89        30\n",
            "      scents       0.92      0.69      0.79        16\n",
            "    skincare       0.68      0.95      0.79        20\n",
            "\n",
            "    accuracy                           0.83        66\n",
            "   macro avg       0.85      0.82      0.82        66\n",
            "weighted avg       0.86      0.83      0.84        66\n",
            "\n"
          ]
        }
      ]
    }
  ]
}